{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25875a7-518f-4020-bbc8-29aa6371dd12",
   "metadata": {},
   "source": [
    "# Generating Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e885b-8b8c-4479-9443-6b323ee51d11",
   "metadata": {},
   "source": [
    "To validate Scanipy, we generate a dataset with Markdown files from LaTeX and PDF papers found in [Arxiv](https://arxiv.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eea46d-24f3-4a04-b9fe-3346b5e0bf61",
   "metadata": {},
   "source": [
    "```powershell\n",
    "pip install -r requirements_data.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644cae9-474b-4ad9-9190-e21ed6f241c9",
   "metadata": {},
   "source": [
    "## 1. Get PDF and TEX files from Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc0257-347e-4851-bb75-8cac80926828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from access_arxiv import choose_topic\n",
    "\n",
    "#choose the topic and the number of papers\n",
    "df = choose_topic('sea',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8257aaec-98c3-4dc6-9c83-1e1dba68290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tar_pdf import downloading_tar_pdf\n",
    "\n",
    "downloading_tar_pdf(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b04f10-e6b0-4136-b047-45ec021bcaf1",
   "metadata": {},
   "source": [
    "## 2. Transform the Tex files in HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d8eff-1cef-4e8f-a41a-f183fad3603b",
   "metadata": {},
   "source": [
    "We use [engrafo](https://github.com/arxiv-vanity/engrafo) to convert the main LaTeX arxiv files into responsive web pages in HTML using [LaTeXML](https://github.com/brucemiller/LaTeXML)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e21e1-21fb-4005-ac49-b70388c91b9c",
   "metadata": {},
   "source": [
    "We run engrafo by using the Docker image. The first step is to run in the powershell:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cfc8f3-75a4-43ba-957d-3fd413f3c74f",
   "metadata": {},
   "source": [
    "```powershell\n",
    "# Assuming your main .tex files are located in the following directory\n",
    "TEX_DIR = \"path\\to\\tex\\files\"\n",
    "\n",
    "# Get a list of all main .tex files in the subdirectories\n",
    "$mainTexFiles = Get-ChildItem -Path $TEX_DIR -Filter \"*.tex\" -File -Recurse | Where-Object { $_.Name -eq ($_.Directory.Name + \".tex\") }\n",
    "\n",
    "# Specify the output folder\n",
    "$outputFolder = \"html\"\n",
    "\n",
    "# Loop through main .tex files and run the Docker command for each\n",
    "foreach ($mainTexFile in $mainTexFiles) {\n",
    "    # Extract the arxiv_id from the directory name\n",
    "    $arxiv_id = $mainTexFile.Directory.Name\n",
    "\n",
    "    # Create the output folder for the current arxiv_id if it doesn't exist\n",
    "    $outputDir = Join-Path -Path $TEX_DIR -ChildPath \"$outputFolder\\$arxiv_id\"\n",
    "    if (-not (Test-Path -Path $outputDir -PathType Container)) {\n",
    "        New-Item -Path $outputDir -ItemType Directory -Force\n",
    "    }\n",
    "    \n",
    "    # Run the Docker command to convert .tex to .html, save it in the output folder\n",
    "    $dockerCmd = \"docker run --volume $($TEX_DIR):/workdir -w /workdir arxivvanity/engrafo:latest engrafo $($arxiv_id)/$($arxiv_id).tex $($outputFolder)/$($arxiv_id)/\"\n",
    "    Invoke-Expression $dockerCmd\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd8dce1-e3a0-47f8-8d1f-f789ddfa9cf0",
   "metadata": {},
   "source": [
    "You will get the html files, along with the images, the css file and the js file inside your output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de248ca4-e56f-4491-bf4f-773c137ef6fd",
   "metadata": {},
   "source": [
    "## 3. Extract figures, captions, tables and section titles from the PDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b321c-fda1-4607-a8cd-f06f36afcde1",
   "metadata": {},
   "source": [
    "Clone the [pdffigures2](https://github.com/allenai/pdffigures2) repository. It is a Scala based project built to extract figures, captions, tables and section titles from scholarly documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6a056-5c06-4422-ba9c-180958f8236c",
   "metadata": {},
   "source": [
    "```powershell\n",
    "git clone https://github.com/allenai/pdffigures2.git\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd2e13-e295-41bf-bfd5-67fcb84b07ea",
   "metadata": {},
   "source": [
    "Fix some bugs with this [pull request](https://github.com/allenai/pdffigures2/commit/d7abe4c5210893e9104fe55707ba4b40eaf6a245)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb36540-fe6c-47e1-9be6-93b8e88790a5",
   "metadata": {},
   "source": [
    "Clone the [almond](https://github.com/almond-sh/almond) repo, to be able to use it as a [Scala](https://scala-lang.org/) kernel for [Jupyter](https://jupyter.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648eebe-a1fd-49c6-ab49-670aa84f6c7a",
   "metadata": {},
   "source": [
    "```powershell\n",
    "git clone https://github.com/almond-sh/almond.git\n",
    "cd almond\n",
    "./mill -i jupyterFast\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512b4a4-c4f3-416f-bff7-ea172a0dfe65",
   "metadata": {},
   "source": [
    "A Scala kernel should open on Jupyter. In the shell, run:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4cdbcd-ded2-48b3-987b-b89e51ec708b",
   "metadata": {},
   "source": [
    "```powershell\n",
    "cd pdffigures2\n",
    "sbt \"runMain org.allenai.pdffigures2.FigureExtractorBatchCli path\\to\\pdffiles -s stat_file.json -m path\\to\\save\\images -d path\\to\\save\\data\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a3233-ce14-48d2-a4c2-072c6417b2dc",
   "metadata": {},
   "source": [
    "The images, figure objects and statistics are going to be seen in the output. Besides, a binary jar file is going to be saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc5289-ebab-4d7b-859d-2fec77e33dc6",
   "metadata": {},
   "source": [
    "## 4. Transform the HTML files in Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272039fb-53c1-4200-b09e-30ca2704ab4f",
   "metadata": {},
   "source": [
    "To call the [Nougat](https://github.com/facebookresearch/nougat) model to get the Markdown files, install the necessary dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e9fec-ddaf-49fa-8b6d-3f2cd1241c3c",
   "metadata": {},
   "source": [
    "```powershell\n",
    "pip install nougat-ocr[dataset]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ed3e4-d807-4218-83ae-ee998c3f341a",
   "metadata": {},
   "source": [
    "Create an environment variable with the path to the binary jar file generated in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a52779-7c0e-4bba-9e01-dd5ddf9fe3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the PDFFIGURES_PATH environment variable\n",
    "os.environ[\"PDFFIGURES_PATH\"] = '../pdffigures2/target/scala-2.12/pdffigures2_2.12-0.1.0.jar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea8e57-67e1-4340-9b9a-8567314531b0",
   "metadata": {},
   "source": [
    "Be careful. The HTML, PDF and JSON files corresponding to the same arxiv id should have the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1cd94-a1c7-4505-a21e-279a0007e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m nougat.dataset.split_htmls_to_pages --html \"path\\to\\html\\files\" --pdfs \"path\\to\\pdf\\files\" --out \"path\\to\\output\" --figure \"path\\to\\json\\data\\files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e047e-f2d4-44cb-b5bd-903b623892d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m nougat.dataset.create_index --dir path\\to\\output --out index.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262f4d15-1f4c-4df3-a3cf-ea42bc1abb0e",
   "metadata": {},
   "source": [
    "The final output is a JSON file containing the image paths, markdown text and meta information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
